{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa589884db43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "def load_results(path_dataset):\n",
    "    \"\"\"load data features.\"\"\"\n",
    "    to_int = dict(s = 1,b = 0)\n",
    "    def convert(s):\n",
    "        return to_int.get(s.decode(\"utf-8\") , 0)\n",
    "    \n",
    "    data = data = np.genfromtxt(path_dataset, delimiter=\",\", skip_header=1, usecols=[1],\n",
    "                                converters={1: convert})\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_data_features(path_dataset):\n",
    "    \"\"\"load data features.\"\"\"\n",
    "    data = data = np.genfromtxt(path_dataset, delimiter=\",\", skip_header=1, \n",
    "                                usecols=tuple(range(2,32)))\n",
    "    \n",
    "    ids = np.genfromtxt(path_dataset, delimiter=\",\", skip_header=1, usecols=[0])\n",
    "    \n",
    "    return data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_polynomial(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    Extended = np.empty((x.shape[0],0))\n",
    "    \n",
    "    for j in range(0, degree+1):\n",
    "        for i in range(x.shape[1]):\n",
    "            Extended = np.c_[Extended, x[:,i]**j]\n",
    "    \n",
    "    return Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_filter(X, y, threshold = 0.01):\n",
    "    \"\"\"Removes features which are correlated with y with less than threshold\"\"\"\n",
    "    abs_corr = np.zeros(X.shape[1])\n",
    "    for index, x in enumerate(X.T):\n",
    "        abs_corr[index] = np.abs(np.corrcoef(y,x.T)[0,1])\n",
    "        \n",
    "    quality = np.where(abs_corr > threshold)\n",
    "    \n",
    "    return X[:,quality[0]], quality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_by_penalized_gradient(y, tx, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descent, using the penalized logistic regression.\n",
    "    Return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss = calculate_loss(y, tx, w) + lambda_ * np.squeeze(w.T.dot(w))\n",
    "    gradient = calculate_gradient(y, tx, w) + 2 * lambda_ * w\n",
    "    w -= gradient*gamma\n",
    "    \n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data, mean = None, sigma = None):\n",
    "    \"\"\"Standardizes the data\"\"\"\n",
    "    if mean is None:\n",
    "        mean = np.nanmean(data[data != -999], axis = 0)\n",
    "    \n",
    "    if sigma is None:\n",
    "        sigma = np.nanstd(data[data != -999], axis = 0)\n",
    "    \n",
    "    output = (data - mean)/sigma\n",
    "    \n",
    "    return output, mean, sigma\n",
    "\n",
    "def standardize_data(data, min_value = None, max_value = None):\n",
    "    \"\"\"maps data to [0,1] range\"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = np.min(data, axis = 0)\n",
    "    \n",
    "    if max_value is None:\n",
    "        max_value = np.max(data, axis = 0)\n",
    "        \n",
    "    output = (data - min_value)/(max_value - min_value)\n",
    "    \n",
    "    return output, min_value, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsets(data, y, ids):\n",
    "    \"\"\"Creates four subsets based on the number of jets,\n",
    "    which is 0, 1 and 2 or 3. 2 and 3 are put in one group,\n",
    "    since they keep same features and have similar correlation patterns\n",
    "    \"\"\"\n",
    "    data_subsets = []\n",
    "    y_subsets = []\n",
    "    ids_subsets = []\n",
    "    for i in range(3):\n",
    "        if i ==2:\n",
    "            mask = data[:,22] >= i\n",
    "        else:\n",
    "            mask = data[:,22] == i\n",
    "        data_subsets.append(data[mask])\n",
    "        if y is not None:\n",
    "            y_subsets.append(y[mask])\n",
    "            \n",
    "        ids_subsets.append(ids[mask])\n",
    "        \n",
    "    return data_subsets, y_subsets, ids_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_variance(data, mask = None):\n",
    "    \"\"\"removes zero variance columns based on the subset\"\"\"\n",
    "    if mask is None:\n",
    "        variance = np.var(data, axis = 0)\n",
    "        mask = np.squeeze(~np.logical_or([variance ==0],[np.isnan(variance)]))\n",
    "        \n",
    "    return data[:, mask[:]], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing(data, median = None):        \n",
    "    \"\"\"replaces nan by median value\"\"\"\n",
    "    if median is None:\n",
    "        median =[]\n",
    "        for j in range(data.shape[1]):\n",
    "            mask = data[:,j] != -999\n",
    "            replace = np.median(data[mask,j])\n",
    "            data[~mask,j] = replace\n",
    "            median.append(replace)\n",
    "    else:\n",
    "        for j in range(data.shape[1]):\n",
    "            mask = data[:,j] != -999\n",
    "            data[~mask,j] = median[j]\n",
    "\n",
    "    return data, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(X_train, X_test, y_train, y_test, ids_train, ids_test):\n",
    "    \"\"\"\n",
    "    Processes the test and training data by:\n",
    "    -splitting data with respect to jet number, creating three groups\n",
    "    -removing zero variance in each subgroup\n",
    "    -removing columns which are lowly correlated to y\n",
    "    -normalizing the data with mean and standard devation \n",
    "    -replacing -999 by median value of column\n",
    "    \"\"\"\n",
    "      \n",
    "    train_subsets, y_train, ids_train = create_subsets(X_train, y_train, ids_train)\n",
    "    test_subsets, _, ids_test = create_subsets(X_test, y_test, ids_test)\n",
    "    \n",
    "    for i in range(3):\n",
    "        # change training sets\n",
    "        train_subsets[i], mean, sigma =  normalize_data(train_subsets[i], mean = None, sigma = None)\n",
    "        train_subsets[i], median = replace_missing(train_subsets[i], median = None)\n",
    "        train_subsets[i], mask = remove_zero_variance(train_subsets[i])\n",
    "        train_subsets[i], quality = correlation_filter(train_subsets[i], y_train[i], threshold = 0.01)\n",
    "        \n",
    "        #change test sets accordingly to training sets\n",
    "        test_subsets[i], _, _ =  normalize_data(test_subsets[i], mean, sigma)\n",
    "        test_subsets[i], _ = replace_missing(test_subsets[i], median)\n",
    "        test_subsets[i], _ = remove_zero_variance(test_subsets[i], mask)\n",
    "        test_subsets[i] = test_subsets[i][:, quality]\n",
    "        \n",
    "    return train_subsets, test_subsets, y_train, y_test, ids_train, ids_test\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cross_terms(data):\n",
    "    \"\"\"Adds cross terms between columns\"\"\"\n",
    "    enriched_data = data\n",
    "    for x1 in data.T:\n",
    "        for x2 in data.T:\n",
    "            if np.sum(x1 - x2) != 0:\n",
    "                enriched_data = np.c_[enriched_data, x1*x2]\n",
    "                \n",
    "    return enriched_data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_log_terms(data):\n",
    "    \"\"\"Adds log terms to data\"\"\"\n",
    "    extended = data\n",
    "    for column in data.T:\n",
    "        if np.sum(column <= -1) == 0:\n",
    "            extended = np.c_[extended, np.log(1+ column)]\n",
    "        \n",
    "    return extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data, degree = None, sqrt = True, log = True, cross_terms = True):\n",
    "    \"\"\"\n",
    "    Adds following features to data set:\n",
    "    -log of features by log(1+x)\n",
    "    -sqrt of features\n",
    "    -polynomial extension of 0 up to degree\n",
    "    -cross terms of features\n",
    "    \"\"\" \n",
    "    #log\n",
    "    if log:\n",
    "        data = add_log_terms(data)\n",
    "        output = data\n",
    "    else:\n",
    "        output = np.empty((data.shape[0],0))\n",
    "        \n",
    "    #polynomial\n",
    "    if degree is not None:\n",
    "        output = np.c_[output, build_polynomial(data, degree)]\n",
    "      \n",
    "    # add sqrt\n",
    "    if sqrt:\n",
    "        output = np.c_[output, np.sqrt(np.abs(data))]\n",
    "        \n",
    "    \n",
    "    if cross_terms:\n",
    "        output = np.c_[output, add_cross_terms(data)]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    \"\"\"compute the loss by mse.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    mse = e.dot(e) / (2 * len(e))\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_solution(X_test, y_result, ids_test_group, ids_test):\n",
    "    \"\"\"\n",
    "    Puts found y values back in right order for the complete data matrix,\n",
    "    since it was split in four groups.\n",
    "    X_test: original, preprocessed test data\n",
    "    y_result: output of created model, list of three vectors containing predictions for group 1,2 and 3\n",
    "    \"\"\"\n",
    "    y_final=[]\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if ids_test[i] in ids_test_group[0]:\n",
    "            index = np.where(ids_test_group[0] == ids_test[i])\n",
    "            y_final.append(y_result[0][index])\n",
    "            \n",
    "        elif ids_test[i] in ids_test_group[1]:\n",
    "            index = np.where(ids_test_group[1] == ids_test[i])\n",
    "            y_final.append(y_result[1][index])\n",
    "            \n",
    "        elif ids_test[i] in ids_test_group[2]:\n",
    "            index = np.where(ids_test_group[2] == ids_test[i])\n",
    "            y_final.append(y_result[2][index])\n",
    "            \n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parameters(X_train, y_train):\n",
    "    \"\"\"Finding best parameters and losses per set\"\"\"\n",
    "    best_parameter_per_set = []\n",
    "    losses_sets =[]\n",
    "    methods = [\"Ridge_regression\"]\n",
    "    degrees = np.linspace(1,22,21, dtype = int)\n",
    "    lambdas = np.logspace(-11,2,22)\n",
    "    for i in range(3):\n",
    "        print(\"Testing for set\",i)\n",
    "        parameters, losses = hyper_optimizing(X_train[i], y_train[i],\n",
    "                                methods, lambdas, degrees)\n",
    "        \n",
    "        best_parameter_per_set.append(parameters)\n",
    "        losses_sets.append(losses)\n",
    "    \n",
    "    return best_parameter_per_set, losses_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_optimizing(X_train, y_train, methods = [\"Ridge_regression\"],\n",
    "                     lambdas = [0.1], degrees = [1], gamma = 0.000001,  max_iter = 1):\n",
    "    \"\"\"Finds best lambda and degree to use on the given data, test possibilities are:\n",
    "    -Ridge regression\n",
    "    -Penalized Logistic regression\"\"\"\n",
    "    \n",
    "    # Check method names are correct\n",
    "    if len([i for i in methods if i in [\"Ridge_regression\", \"Penalized_logistic\"]]) < len(methods):\n",
    "        raise NameError(\"At least one method is wrong\")\n",
    "        \n",
    "    all_F_scores = np.zeros((len(methods), len(degrees), len(lambdas)))\n",
    "    best_parameters = np.zeros((len(methods), 2))\n",
    "    \n",
    "    for degree_index, degree in enumerate(degrees):\n",
    "        X_train_ex = add_features(X_train, degree = degree)\n",
    "    \n",
    "        for method_index, method in enumerate(methods):\n",
    "            \n",
    "            if method == \"Ridge_regression\":\n",
    "                seed = 1\n",
    "                k_fold = 5\n",
    "                k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "                print(\"Start ridge regression test for degree\", str(degree),\"...\")\n",
    "                for index, lambda_ in enumerate(lambdas):\n",
    "                    F_scores_te = []\n",
    "                    for k in range(k_fold):\n",
    "                        F_score_te = cross_validation_ridge(y_train, X_train_ex, k_indices, k, lambda_)\n",
    "                        F_scores_te.append(F_score_te)\n",
    "                    all_F_scores[method_index, degree_index, index] = np.mean(F_scores_te)\n",
    "                 \n",
    "                # Show percantage of correct results for this degree\n",
    "                min_lambda = lambdas[np.argmax(all_F_scores[method_index, degree_index,:])]\n",
    "                print(\"Highest F_score for lambda:\", min_lambda, \"is:\", max(all_F_scores[method_index, degree_index,:]))\n",
    "                \n",
    "                \n",
    "            elif method == \"Penalized_logistic\":\n",
    "                #less k-fold for reason of speed\n",
    "                seed = 1\n",
    "                k_fold = 1\n",
    "                k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "                print(\"Start penalized_logistic test...\")\n",
    "                for index, lambda_ in enumerate(lambdas):\n",
    "                    F_scores_te = []\n",
    "                    for k in range(k_fold):\n",
    "                        F_score_te, _ = cross_validation_logistic(y_train, X_train_ex, k_indices,\n",
    "                                                    k, lambda_, gamma = 0.000001, max_iter = max_iter)\n",
    "                        F_scores_te.append(F_score_te)\n",
    "                    all_F_scores[method_index, degree_index, index] = np.mean(F_scores_te) \n",
    "                \n",
    "                # Show percantage of correct results for this degree\n",
    "                min_lambda = lambdas[np.argmax(all_F_scores[method_index, degree_index,:])]\n",
    "                print(\"Highest F_score is:\", max(all_F_scores[method_index, degree_index,:]),\"for lambda:\", min_lambda)\n",
    "                \n",
    "            \n",
    "    for k  in range(len(methods)):\n",
    "        max_F = np.argmax(all_F_scores[k,:,:], axis = 0)\n",
    "        best_parameters[k,0] = lambdas[max_F[0]]\n",
    "        best_parameters[k,1] = degrees[max_F[1]]\n",
    "        \n",
    "    return best_parameters, all_F_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_result(y_found, y_real):\n",
    "    y_found[y_found<0.5]=0\n",
    "    y_found[y_found>=0.5]=1\n",
    "    summ = y_found + y_real\n",
    "    TP = sum(summ == 2)\n",
    "    TN = sum(summ == 0)\n",
    "    diff = y_found - y_real\n",
    "    FP = sum(diff == 1)\n",
    "    FN = sum(diff == -1)\n",
    "    accuracy = (TP+TN)/(TP +TN +FP + FN)\n",
    "    F_score = TP/(TP + 0.5 * (FP +FN))\n",
    "    recall = TP/(TP + FN)\n",
    "    precision = TP/(TP + FP)\n",
    "    return precision, recall, F_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_ridge(y, x, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    y_test = y[k_indices[k]]\n",
    "    x_test = x[k_indices[k], :]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_train = y[tr_indice]\n",
    "    x_train = x[tr_indice, :]\n",
    "\n",
    "    w = ridge_regression(y_train, x_train, lambda_)\n",
    "    # calculate the loss for train and test data:\n",
    "    #loss_te = np.sqrt(2*compute_mse(y_test, x_test, w))\n",
    "    # Calculate F_score, seems more reliable to compare different degrees\n",
    "    y_new = x_test @ w\n",
    "    precision, recall, F_score, accuracy = quantify_result(y_new, y_test)\n",
    "    \n",
    "    return F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_logistic(y, x, k_indices, k,lambda_, gamma,max_iter):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # split according to k_indices\n",
    "    y_test = y[k_indices[k]]\n",
    "    x_test = x[k_indices[k], :]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_train = y[tr_indice]\n",
    "    x_train = x[tr_indice, :]\n",
    "    \n",
    "    w = np.zeros((x.shape[1], 1))\n",
    "    threshold = 1e-8\n",
    "    losses = []\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_penalized_gradient(y_train, x_train, w, gamma, lambda_)\n",
    "        # log info\n",
    "        if iter % 999 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # check loss actually decreases, if not decrease gamma\n",
    "        if iter > 0:\n",
    "            if loss > losses[-1]:\n",
    "                gamma = gamma/2\n",
    "            \n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "        \n",
    "    # calculate the loss for train and test data:\n",
    "  #  loss_te = calculate_loss(y_test, x_test, w)\n",
    "    \n",
    "    # Calculate F_score, seems more reliable to compare different degrees\n",
    "    y_new = x_test @ w\n",
    "    precision, recall, F_score, accuracy = quantify_result(y_new, y_test)\n",
    "    \n",
    "    return F_score, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"ridge regression\"\"\"\n",
    "    if len(tx.shape) > 1:\n",
    "        w = np.linalg.solve(tx.T @ tx + (2*tx.shape[0]*lambda_)*np.identity(tx.shape[1]), tx.T @ y)\n",
    "    else:\n",
    "        w = 1/(tx.T @ tx + lambda_) * tx.T @ y                        \n",
    "\n",
    "    return w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"applies the sigmoid function on t.\"\"\"\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"computes the loss: negative log likelihood.\"\"\"\n",
    "    inter_y = y.reshape(len(y),1)\n",
    "    z = tx @ w\n",
    "    a = np.sum(np.log(1 + np.exp(z)))\n",
    "    b = inter_y.T @ z\n",
    "    loss = a - b\n",
    "    return np.squeeze(loss)\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"computes the gradient of loss.\"\"\"\n",
    "    inter_y = y.reshape(len(y),1)\n",
    "    gradient = tx.T @ (sigmoid(tx @ w) - inter_y)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_ridge(X_train, y_train, X_test, y_test, lambda_):\n",
    "    \"\"\"prints accuracy of ridge regression\"\"\"\n",
    "    w = ridge_regression(y_train, X_train, lambda_)\n",
    "    y_new = X_test @ w\n",
    "    precision, recall, F_score, accuracy = quantify_result(y_new, y_test)\n",
    "    print(\"Accuracy of the predictions is:\",\n",
    "          str(accuracy), \" and F-score is:\", str(F_score), \"with lambda:\",lambda_)\n",
    "    print(\"Precision is:\",str(precision), \"and recall is:\",str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_logistic(X_train, y_train, X_test, y_test, lambda_, gamma = 0.000001):\n",
    "    \"\"\"prints accuracy of logistic regression\"\"\"\n",
    "    w = np.zeros((x.shape[1], 1))\n",
    "    _, w = learning_by_penalized_gradient(y_train, X_train, w, gamma, lambda_)\n",
    "    y_new = X_test @ w\n",
    "    precision, recall, F_score, accuracy = quantify_result(y_new, y_test)\n",
    "    print(\"Accuracy of the predictions is:\",\n",
    "          str(accuracy), \" and F-score is:\", str(F_score), \"with lambda:\",lambda_)\n",
    "    print(\"Precision is:\",str(precision), \"and recall is:\",str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% load data and process data\n",
    "path =  \"data\"\n",
    "X_train, ids_train = load_data_features(path +\"/train.csv\")\n",
    "y_train = load_results(path +\"/train.csv\")\n",
    "\n",
    "X_test, ids_test = load_data_features(path +\"/test.csv\")\n",
    "\n",
    "#X_train, y_train, ids_train = X[:int(0.8*len(X)),:], y[:int(0.8*len(X))], ids[:int(0.8*len(X))]\n",
    "#X_test, y_test, ids_test = X[int(0.8*len(X)):,:], y[int(0.8*len(X)):], ids[int(0.8*len(X)):]\n",
    "\n",
    "X_train, X_test_pro, y_train, _, ids_tr_group, ids_test_group = process_data(X_train, \n",
    "                                                    X_test, y_train, None, ids_train, ids_test)\n",
    "\n",
    "best_parameter_per_set, losses_per_set = find_parameters(X_train, y_train)\n",
    "y_result = []\n",
    "for i in tqdm(range(3)):\n",
    "    lambda_ = best_parameter_per_set[i][0,0]\n",
    "    degree = int(best_parameter_per_set[i][0,1])\n",
    "    X_train_ex = add_features(X_train[i], degree = degree)\n",
    "    X_test_pro_ex = add_features(X_test_pro[i], degree = degree)\n",
    "    #show_result_ridge(X_train_ex, y_train[i], X_test_pro_ex, y_test_pro[i], lambda_)\n",
    "    \n",
    "    w = ridge_regression(y_train[i], X_train_ex, lambda_)\n",
    "    y_result.append(X_test_pro_ex @ w)\n",
    "\n",
    "y_final = stitch_solution(X_test, y_result, ids_test_group, ids_test)\n",
    "y_test = np.reshape(y_test, (len(y_test),1))\n",
    "y_final = np.array(y_final)\n",
    "quantify_result(y_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_type() missing 1 required positional argument: 'types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7aab4b7de338>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcheck_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: check_type() missing 1 required positional argument: 'types'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
